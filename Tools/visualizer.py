""" This scipt visualises data generated by the program. It can render png images coming from the sensors, LIDAR point cloud, 
semantic point cloud and depth point cloud. To  run the script, you need to provide the path to the scenario
directory. You can also use the optional arguments to render only specific plots. The script also has a few
constants that can be modified to change the appearance of the plots. 

Usage: python visualizer.py <path_to_scenario> [-c] [-p] [-s] [-d] [-a] [-l]
-c --camera-feed: Render camera feed
-p --point-cloud: Render LIDAR point cloud
-s --semantic-cloud: Render semantic point cloud
-d --depth-cloud: Render deph point cloud
-a --all: Render all plots (Default)
-l --last: Render the first scenario of last output
"""

import argparse
import base64
import csv
import os
import sys

import cv2

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import plotly.graph_objects as go
from plotly.subplots import make_subplots
from Tools.util import *
from pathlib import Path
from tqdm import tqdm

output = "Final_Output_20_24-05_02_2024"
out = "Images"
scenario = "Scenario_0"
ffmpeg_cmd = "ffmpeg -r 12 -i frame_%00d.png -c:v libx264 -profile:v high -crf 12 -pix_fmt yuv420p -y img3.mp4"

FRAME_DURATION = 200
FRAME_DURATION_PT = 300

FRAME_REDUCE = 4
PRUNE = 1

HOR_SPACING = 0.03
# IMG_SIZE = 0.325
IMG_SIZE = 0.3
IMG_Y_POS = 0.38
MIN_DIST = 0.05

VOXEL_EXPAND_FACTOR = 2 # Expand the voxel size by this factor to make the voxel more visible
VOXEL_RANGE = ((425, 575), (425, 575), (-25, 125))
VOXEL_TEST = False

def main():
    parser = argparse.ArgumentParser(description='Visualize the data')
    parser.add_argument( 'scenario_path', type=str, help='Path to the scenario')
    parser.add_argument( '-c', '--camera-feed', action="store_true", help='Render camera feed')
    parser.add_argument( '-p', '--point-cloud', action="store_true",  help='Render LIDAR point cloud')
    parser.add_argument( '-s', '--semantic-cloud', action="store_true", help='Render semantic point cloud')
    parser.add_argument('-v', '--voxel', action="store_true", help='Render voxelized point cloud')
    parser.add_argument( '-a', "--all", action="store_true", help='Render all plots (Default)')
    parser.add_argument('-f', '--frame', type=int, default=0, help='Render all data on a specific frame')
    parser.add_argument('-i', '--images', action="store_true", help='Render all data on all frames')
    parser.add_argument('-l', '--last', action="store_true", help="Reder the first scenario of last output" )
    
    args = parser.parse_args()
    data_path = Path(args.scenario_path)
    if not data_path.exists():
        print("The target scenario directory doesn't exist")
        raise SystemExit(1)
    else:
        print(f"Directory Found")

    render_all = args.all
    render_p = args.point_cloud
    render_c = args.camera_feed
    render_s = args.semantic_cloud
    render_l = args.last
    render_v = args.voxel
    render_f = args.frame
    render_images = args.images

    if render_l:
        last_output = get_last_output_dir()
        last_scenario = get_first_scenario(last_output)
        data_path = last_scenario
        print(f"Rendering the first scenario of the last output: {last_output}")
    if not render_p and not render_c and not render_s and not render_v and not render_f and not render_images:
        render_all = True

    data = process_data(data_path, render_all, render_p, render_c, render_s, render_v, render_f, render_images)

    if (render_all or render_c):
        cam_fig = draw_cam(data)
        cam_fig.show()

    if (render_all or render_p):
        pt_fig = draw_pt(data, "npy")
        pt_fig.show()

    if (render_all or render_s):
        sem_pt_fig = draw_pt(data, "sem_npy")
        sem_pt_fig.show()

    if (render_v):
        if not VOXEL_TEST:
            voxel_fig = draw_pt(data, "voxel")
            voxel_fig.show()
        else:    
            voxel_to_vertices(data["voxel"][0], 1)  

    if render_f:
        print(f"Rendering frame {render_f}")
        
        com_fig = draw_combined_frame(data, render_f)
        com_fig.show()
        com_fig.write_html(f"{out}/frame_{render_f}.html")

    if render_images:
        # Delete all the images in the output directory
        files = get_files(out)
        for file in files:
            os.remove(f"{out}/{file}")
        
        print(f"Rendering video")
        for i in tqdm(data["frame_id"], total=len(data["frame_id"])):
            frame_id = int(i)
            com_fig = draw_combined_frame(data, frame_id)
            com_fig.write_image(f"{out}/frame_{frame_id}.png", width=1920, height=1080)        



def action_path_to_array(action_path):
    values_list = []
    itr = list(get_files(action_path))
    for file_name in tqdm(itr, total=len(itr)):
        with open(os.path.join(action_path, file_name), 'r') as file:
            csvreader = csv.reader(file, delimiter=';')
            value = []
            for i, row in enumerate(csvreader):
                if (i == 0):
                    value.append(int(row[1]))
                if (i == 4):
                    value.append(float(row[1]))
                if (i == 5):
                    value.append(float(row[1]))
                if (i == 6):
                    value.append(float(row[1]))
                if (i == 7):
                    value.append(float(row[1]))
            values_list.append(value)
    values_array = np.array(values_list)
    values_array.sort(axis=0)
    return values_array

def img_path_to_array(image_path):
    values_list = []
    itr = list(get_files(image_path))
    for file_name in tqdm(itr, total=len(itr)):
        file_path = image_path + os.sep + file_name
        img = cv2.imread(file_path)
        # TODO: Raise an error if an image is corrupted
        _, buffer = cv2.imencode('.png', img)
        img = base64.b64encode(buffer)
        img_frame_id = int(file_name.split('_')[-1].split('.')[0])
        values_list.append((img_frame_id, img))

    img_sorted = sorted(values_list, key=lambda x: x[0])
    return np.array([x[1] for x in img_sorted])

def depth_path_to_array(depth_path):
    values_list = []
    itr = list(get_files(depth_path))
    for file_name in tqdm(itr, total=len(itr)):
        org_img = cv2.imread(depth_path + os.sep + file_name)
        img = org_img.astype(np.float32)
        img = np.dot(img[:, :, :3], [65536.0, 256.0, 1.0])
        img /= 16777215.0

        normalized_depth = img
        # Convert to logarithmic depth.
        logdepth = np.ones(normalized_depth.shape) + \
                   (np.log(normalized_depth) / 5.70378)
        logdepth = np.clip(logdepth, 0.0, 1.0)

        # Invert logdepth so 1 is near and 0 is far
        logdepth = 1.0 - logdepth

        logdepth *= 255.0
        img = logdepth
        img = img.astype(np.uint8)
        img = cv2.applyColorMap(img, cv2.COLORMAP_MAGMA)

        # TODO: Raise an error if an image is corrupted
        _, buffer = cv2.imencode('.png', img)
        img_encod = base64.b64encode(buffer)

        img_frame_id = int(file_name.split('_')[-1].split('.')[0])
        values_list.append((img_frame_id, img_encod, org_img))

    img_sorted = sorted(values_list, key=lambda x: x[0])
    return (np.array([x[1] for x in img_sorted]), np.array([x[2] for x in img_sorted]))

def sem_path_to_array(sem_path):
    values_list = []
    itr = list(get_files(sem_path))
    for file_name in tqdm(itr, total=len(itr)):
        org_img = cv2.imread(sem_path + os.sep + file_name)
        img = labels_to_cityscapes_palette(org_img)
        img_float32 = np.float32(img)
        # print(org_img.shape, img.shape)
        im_bgr = cv2.cvtColor(img_float32, cv2.COLOR_RGB2BGR)

        _, buffer = cv2.imencode('.png', im_bgr)
        img_encod = base64.b64encode(buffer)
        img_frame_id = int(file_name.split('_')[-1].split('.')[0])
        values_list.append((img_frame_id, img_encod, org_img))

    img_sorted = sorted(values_list, key=lambda x: x[0])
    return (np.array([x[1] for x in img_sorted]), np.array([x[2] for x in img_sorted]))

def npy_path_to_array(npy_path):
    values_list = []
    itr = list(get_files(npy_path))
    for file_name in tqdm(itr, total=len(itr)):
        npy = np.load(npy_path + os.sep + file_name)
        pruned = []
        for i, value in enumerate(npy):
            if i % PRUNE == 0:
                pruned.append(value)
        pruned = np.array(pruned)

        npy_frame_id = int(file_name.split('_')[-1].split('.')[0])
        # print(npy_frame_id, file_name, npy.shape)
        values_list.append((npy_frame_id, pruned))

    # print(values_list)
    npy_sorted = sorted(values_list, key=lambda x: x[0])

    return [x[1] for x in npy_sorted]

def vxl_path_to_array(vxl_path):
    values_list= []
    itr = list(get_files(vxl_path))
    for file_name in tqdm(itr, total=len(itr)):
        npy = np.load(vxl_path + os.sep + file_name)
        # remove points outside the VOXEL_RANGE
        npy = npy[(npy[:, 0] > VOXEL_RANGE[0][0]) & (npy[:, 0] < VOXEL_RANGE[0][1])]
        npy = npy[(npy[:, 1] > VOXEL_RANGE[1][0]) & (npy[:, 1] < VOXEL_RANGE[1][1])]
        npy = npy[(npy[:, 2] > VOXEL_RANGE[2][0]) & (npy[:, 2] < VOXEL_RANGE[2][1])]
        # expand the voxel size to make it more visible
        npy = npy * [VOXEL_EXPAND_FACTOR, VOXEL_EXPAND_FACTOR, VOXEL_EXPAND_FACTOR, 1]
        pruned = []
        for i, value in enumerate(npy):
            if i % PRUNE == 0:
                pruned.append(value)
        pruned = np.array(pruned)
        
        npy_frame_id = int(file_name.split('_')[-1].split('.')[0])
        # print(npy_frame_id, file_name, npy.shape)
        values_list.append((npy_frame_id, pruned))
    
    # print(values_list)
    npy_sorted = sorted(values_list, key=lambda x: x[0])

    return [x[1] for x in npy_sorted]

def process_data(data_path, render_all, render_p, render_c, render_s, render_v, render_f, render_images):
    action_path = find_directory("ACTION*", data_path)
    rgb_imgages_path = find_directory("RGB-CAM*", data_path)
    inst_imgs_path = find_directory("INSTANCE-CAM*", data_path)
    sem_imgs_path = find_directory("SEMANTIC-CAM*", data_path)
    depth_imgs_path = find_directory("DEPTH_CAM*", data_path)
    npy_path = find_directory("LIDAR*", data_path)
    sem_npy_path = find_directory("SEMANTIC-LIDAR*", data_path)


    if render_f or render_images:
        render_all = True

    # Action Data Processing
    print("\nProcessing action data...")
    values_array = action_path_to_array(action_path)
    data = {
        "frame_id": values_array[:, 0],
        "speed": values_array[:, 1],
        "throttle": values_array[:, 2],
        "steer": values_array[:, 3],
        "brake": values_array[:, 4],
    }

    data["scenario"] = data_path.name
    data["frame_id"] -= data["frame_id"].min()

    # RGB Images Processing
    print("\nProcessing RGB images...")
    data["rgb_img"] = img_path_to_array(rgb_imgages_path)

    # Instance Images Processing
    if render_all or render_c:
        print("\nProcessing instance images...")
        data["inst_img"] = img_path_to_array(inst_imgs_path)

        # Semantic Images Processing
        print("\nProcessing semantic images...")
        data["sem_img"], data["sem_org"] = sem_path_to_array(sem_imgs_path)

        # Depth Images Processing
        print("\nProcessing depth images...")
        data["depth_img"], data["3d_depth"] = depth_path_to_array(depth_imgs_path)

    if render_all or render_p:
        # Point Cloud Processing
        print("\nProcessing LIDAR point cloud...")
        data["npy"] = npy_path_to_array(npy_path)

    if  render_v or render_all:
        # Voxelized Point Cloud Processing
        try:
            vxl_path = find_directory("VOXEL*", data_path)
        except:
            print("Voxelized point cloud not found")
            raise ValueError

        print("\nProcessing voxelized point cloud...")
        data["voxel"] = vxl_path_to_array(vxl_path)

    if render_all or render_s:
        # Semantic Point Cloud Processing
        print("\nProcessing Semantic point cloud...")
        sem_npy = npy_path_to_array(sem_npy_path)

        res = []
        for pt in sem_npy:
            res.append(point_cloud_labels_to_cityscapes_palette(pt))
        data["sem_npy"] = res

    return data

def voxel_to_vertices(ptc, voxel_size):
    # generate cube vertices for each voxel in the point cloud with a center at x, y, z and size s
    generate_cubes = lambda arr, s: np.array([arr + np.array([i, j, k]) * s for i in [-1, 1] for j in [-1, 1] for k in [-1, 1]])
    # generate vertices for all voxels in the point cloud
    if not VOXEL_TEST:
        first_ptc = ptc
    else:
        first_ptc = ptc[:1]
    first_cube_vertices = generate_cubes(first_ptc[:, :3], voxel_size)
    ptc_color = point_cloud_labels_to_cityscapes_palette(first_ptc)[:, 3:6]
    
    # add color to vertex array so the shape of the array changes from (8, n, 3) to (8, n, 6)
    color_per_vertex = np.array([ptc_color for i in range(8)])
    first_cube_vertices = np.concatenate([first_cube_vertices, color_per_vertex], axis=2)
    first_ptc_len = first_ptc.shape[0]
    # concatenate all the vertices of the cubes into one array with each vertexes of one cube being consecutivilly placed
    first_cube_vertices = np.concatenate(first_cube_vertices, axis=0)

    # i, j and k give the vertices of triangles
    cube_voxel_indexes = np.array([ 
        [1, 3, 1, 5, 0, 2, 1, 3, 2, 3, 4, 6],
        [0, 1, 0, 1, 2, 6, 3, 7, 3, 7, 5, 5],
        [2, 2, 4, 4, 4, 4, 5, 5, 6, 6, 6, 7]])
    
    first_cube_indexes = np.array([i + cube_voxel_indexes*first_ptc_len for i in range(first_ptc_len)])
    # print("shape of first cube indexes: ", first_cube_indexes.shape, first_cube_indexes[:, 0].flatten())
    
    # for i, vertex in enumerate(first_cube_vertices):
    #     print(f"Vertex {i}: {vertex}")

    # print(f"First two cubes position: {first_ptc} vertices: {first_cube_vertices} indexes: {first_cube_indexes}")
    # print(f"Flattened i indexes: {first_cube_indexes[:, 0, :].flatten()}, j indexes: {first_cube_indexes[:, 1, :].flatten()}, k indexes: {first_cube_indexes[:, 2, :].flatten()}")
    if VOXEL_TEST:
        print(f"First two cubes position: {first_ptc} vertices: {first_cube_vertices} indexes: {first_cube_indexes}")
        print(f"Color of the first two cubes: {ptc_color}")
        # Test the voxelization
        fig = go.Figure(data=[
            go.Mesh3d(
                x=first_cube_vertices[:, 0].flatten(),
                y=first_cube_vertices[:, 1].flatten(),
                z=first_cube_vertices[:, 2].flatten(),
                i = first_cube_indexes[:, 0, :].flatten(),
                j = first_cube_indexes[:, 1, :].flatten(),
                k = first_cube_indexes[:, 2, :].flatten(),
                vertexcolor=first_cube_vertices[:, 3:6],
                showscale=False,
                name='voxel',)

            ])

        fig.show() 
    return first_cube_vertices, first_cube_indexes

# Camera feed figure
def draw_cam(data):
    print("\nGenerating camera feed figure...")
    max_frames = data["frame_id"].max()
    cam_fig = make_subplots(rows=2, cols=4,
                            specs=[[{"type": "scatter"}, {"type": "scatter"}, {"type": "scatter"}, {"type": "scatter"}],
                                   [{"type": "image", "rowspan": 1}, {"type": "image", "rowspan": 1},
                                    {"type": "image", "rowspan": 1},
                                    {"type": "image", "rowspan": 1}],
                                   ],
                            subplot_titles=(
                                "Speed", "Steer", "Throttle", "Brake", "RGB Image", "Instance Image", "Semantic Image",
                                "Depth Image"),
                            vertical_spacing=0.2,
                            horizontal_spacing=HOR_SPACING)

    cam_fig.add_scatter(x=data["frame_id"], y=data["speed"], mode="lines", name="speed", row=1, col=1)
    cam_fig.add_scatter(x=[data["frame_id"][0]], y=[data["speed"][0]], mode="markers",
                        marker=dict(color="red", size=10), name="speed_ball",
                        showlegend=False, row=1, col=1)

    cam_fig.add_scatter(x=data["frame_id"], y=data["throttle"], mode="lines", name="throttle", row=1, col=3)
    cam_fig.add_scatter(x=[data["frame_id"][0]], y=[data["throttle"][0]], mode="markers",
                        marker=dict(color="red", size=10),
                        name="throttle_ball", showlegend=False, row=1, col=3)

    cam_fig.add_scatter(x=data["frame_id"], y=data["steer"], mode="lines", name="steer", row=1, col=2)
    cam_fig.add_scatter(x=[data["frame_id"][0]], y=[data["steer"][0]], mode="markers",
                        marker=dict(color="red", size=10), showlegend=False,
                        name="steer_ball", row=1, col=2)

    cam_fig.add_scatter(x=data["frame_id"], y=data["brake"], mode="lines", name="brake", row=1, col=4)
    cam_fig.add_scatter(x=[data["frame_id"][0]], y=[data["brake"][0]], mode="markers",
                        marker=dict(color="red", size=10), showlegend=False,
                        name="brake_ball", row=1, col=4)

    cam_fig.update_layout(
        images=[
            dict(
                source='data:image/png;base64,{}'.format(data["rgb_img"][0].decode()),
                xref="paper", yref="paper",
                x=0, y=IMG_Y_POS,
                sizex=IMG_SIZE, sizey=IMG_SIZE,
                xanchor="left",
                yanchor="top",
            ),
            dict(
                source='data:image/png;base64,{}'.format(data["inst_img"][0].decode()),
                xref="paper", yref="paper",
                x=0.26, y=IMG_Y_POS,
                sizex=IMG_SIZE, sizey=IMG_SIZE,
                xanchor="left",
                yanchor="top",
            ),
            dict(
                source='data:image/png;base64,{}'.format(data["sem_img"][0].decode()),
                xref="paper", yref="paper",
                x=0.515, y=IMG_Y_POS,
                sizex=IMG_SIZE, sizey=IMG_SIZE,
                xanchor="left",
                yanchor="top",
            ),
            dict(
                source='data:image/png;base64,{}'.format(data["depth_img"][0].decode()),
                xref="paper", yref="paper",
                x=0.775, y=IMG_Y_POS,
                sizex=IMG_SIZE, sizey=IMG_SIZE,
                xanchor="left",
                yanchor="top",
            ),
        ],
    )
    frames = []
    frames = [go.Frame(
        data=[
            go.Scatter(visible=True),
            go.Scatter(x=[data["frame_id"][k]], y=[data["speed"][k]], visible=True),
            go.Scatter(visible=True),
            go.Scatter(x=[data["frame_id"][k]], y=[data["throttle"][k]], visible=True),
            go.Scatter(visible=True),
            go.Scatter(x=[data["frame_id"][k]], y=[data["steer"][k]], visible=True),
            go.Scatter(visible=True),
            go.Scatter(x=[data["frame_id"][k]], y=[data["brake"][k]], visible=True),
        ],
        layout=dict(images=[
            dict(source=f"data:image/png;base64,{data['rgb_img'][k].decode()}"),
            dict(source=f"data:image/png;base64,{data['inst_img'][k].decode()}"),
            dict(source=f"data:image/png;base64,{data['sem_img'][k].decode()}"),
            dict(source=f"data:image/png;base64,{data['depth_img'][k].decode()}"),
        ]),

        name=f"{data['frame_id'][k]}",
        traces=[0, 1, 2, 3, 4, 5, 6, 7]) for k in tqdm(range(len(data["frame_id"])))]  #

    cam_fig.frames = frames
    cam_fig.update_layout(template='plotly_dark')

    cam_fig.update_layout(
        title=f"<b>Camera feed of {scenario}</b>",
    )
    cam_sliders = [
        {
            "pad": {"b": 10, "t": 50},
            "len": 1.0,
            "x": 0,
            "y": 0,
            "steps": [
                {
                    "args": [[f.name], frame_args(FRAME_DURATION)],
                    "label": f"frame {int(float(f.name))}",

                    "method": "animate",
                }
                for k, f in enumerate(cam_fig.frames)
            ],
        }
    ]

    cam_fig.update_layout(sliders=cam_sliders, updatemenus=[
        dict(type="buttons", buttons=[AnimationButtons.play(), AnimationButtons.pause()],
             showactive=False,
             x=0.5, y=0.09,
             direction="left",
             pad={"r": 10, "t": 87},
             xanchor="right",
             yanchor="top")])

    cam_fig.update_layout(
        legend=dict(x=0.98, y=1.08, xanchor='right', yanchor='top'),
        legend_orientation='h',
    )
    # Update throttle range
    cam_fig.update_layout(
        xaxis2=dict(range=[-1, max_frames + 1]),
        yaxis2=dict(range=[-1.1, 1.1]),
        xaxis3=dict(range=[-1, max_frames + 1]),
        yaxis3=dict(range=[-0.1, 1.1]),
        xaxis4=dict(range=[-1, max_frames + 1]),
        yaxis4=dict(range=[-0.1, 1.1]), )

    return cam_fig

# Point Cloud figure
def draw_pt(data, pt_type):
    if pt_type == "npy":
        print("\nGenerating point cloud figure...")
    elif pt_type == "sem_npy":
        print("\nGenerating semantic point cloud figure...")
    elif pt_type == "voxel":
        print("\nGenerating voxelized point cloud figure...")
    
    pt_fig = make_subplots(rows=4, cols=4,
                           specs=[[{"type": "scatter", "rowspan": 2}, {"type": "scatter", "rowspan": 2},
                                   {"type": "scatter3d", "rowspan": 4, "colspan": 2}, None],
                                  [None, None, None, None],
                                  [{"type": "image", "rowspan": 2}, {"type": "scatter"}, None, None],
                                  [None, {"type": "scatter"}, None, None]]
                           ,
                           subplot_titles=("Speed", "Steer", "Point Cloud", "RGB Image", "Throttle", "Brake"),
                           vertical_spacing=0.15)

    # pt_fig = FigureResampler(pt_fig)
    pt_fig.add_scatter(x=data["frame_id"], y=data["speed"], mode="lines", name="speed", showlegend=False, row=1, col=1)
    pt_fig.add_scatter(x=[data["frame_id"][0]], y=[data["speed"][0]], mode="markers", marker=dict(color="red", size=10),
                       name="speed_ball",
                       showlegend=False, row=1, col=1)

    pt_fig.add_scatter(x=data["frame_id"], y=data["throttle"], mode="lines", name="throttle", showlegend=False, row=3,
                       col=2)
    pt_fig.add_scatter(x=[data["frame_id"][0]], y=[data["throttle"][0]], mode="markers",
                       marker=dict(color="red", size=10),
                       name="throttle_ball", showlegend=False, row=3, col=2)

    pt_fig.add_scatter(x=data["frame_id"], y=data["steer"], mode="lines", name="steer", showlegend=False, row=1, col=2)
    pt_fig.add_scatter(x=[data["frame_id"][0]], y=[data["steer"][0]], mode="markers", marker=dict(color="red", size=10),
                       name="steer_ball",
                       showlegend=False, row=1, col=2)

    pt_fig.add_scatter(x=data["frame_id"], y=data["brake"], mode="lines", name="brake", showlegend=False, row=4, col=2)
    pt_fig.add_scatter(x=[data["frame_id"][0]], y=[data["brake"][0]], mode="markers", marker=dict(color="red", size=10),
                       name="brake_ball",
                       showlegend=False, row=4, col=2)
    if (pt_type == "npy"):
        pt_fig.add_scatter3d(x=data[pt_type][0][:, 0], y=data[pt_type][0][:, 1], z=data[pt_type][0][:, 2],
                             mode='markers', showlegend=False, marker=dict(size=1, color=data[pt_type][0][:, 3]),
                             name="point cloud", row=1, col=3)
    elif (pt_type == "sem_npy"):
        pt_fig.add_scatter3d(x=data[pt_type][0][:, 0], y=data[pt_type][0][:, 1], z=data[pt_type][0][:, 2],
                            mode='markers', showlegend=False, marker=dict(size=1, color=data[pt_type][0][:, 3:6]),
                            name ="point cloud", row=1, col=3)
    elif (pt_type == "voxel"):
        voxel_size = 1
        vertices, indexes = voxel_to_vertices(data[pt_type][0], voxel_size)
        pt_fig.add_mesh3d(
            x=vertices[:, 0].flatten(),
            y=vertices[:, 1].flatten(),
            z=vertices[:, 2].flatten(),
            i = indexes[:, 0, :].flatten(),
            j = indexes[:, 1, :].flatten(),
            k = indexes[:, 2, :].flatten(),
            vertexcolor=vertices[:, 3:6],
            showscale=False,
            name='voxel',
            row=1, col=3
        )
    else:
        print("Invalid point cloud type")
        raise ValueError
        # Plot an arrow for the direction of the car
    arrow_scale = 1
    arrow_end = [5, 0, 0] * arrow_scale
    arrow_tip_ratio = 0.9
    arrow_starting_ratio = 0.95

    trace1 = go.Scatter3d(
        x=[0],
        y=[0],
        z=[0],
        mode='markers',
        name='markers',
        showlegend=False,
        marker=dict(color='green', size=3),
    )

    trace2 = go.Scatter3d(
        x=[0, arrow_end[0]],
        y=[0, arrow_end[1]],
        z=[0, arrow_end[2]],
        mode='lines',
        showlegend=False,
        line=dict(width=7, color='rgb(0, 255, 0)')
    )

    trace3 = go.Cone(
        x=[arrow_starting_ratio * arrow_end[0]],
        y=[arrow_starting_ratio * arrow_end[1]],
        z=[arrow_starting_ratio * arrow_end[2]],
        u=[arrow_tip_ratio * (arrow_end[0])],
        v=[arrow_tip_ratio * (arrow_end[1])],
        w=[arrow_tip_ratio * (arrow_end[2])],
        showlegend=False,
        showscale=False,
        colorscale=[[0, 'rgb(0,255,0)'], [1, 'rgb(0,255,0)']]
    )
    pt_fig.add_traces([trace1, trace2, trace3])

    pt_fig.update_layout(
        images=[
            dict(
                source='data:image/png;base64,{}'.format(data["rgb_img"][0].decode()),
                xref="paper", yref="paper",
                x=0, y=0.38,
                sizex=0.325, sizey=0.325,
                xanchor="left",
                yanchor="top",
            ),
        ],
        template='plotly_dark'
    )
    pt_frames = []
    for k in tqdm(range(len(data["frame_id"]))):
        # Skip some frames to reduce the size of the semantic point cloud plot
        if k % FRAME_REDUCE:
            continue

        update = [
            go.Scatter(visible=True),
            go.Scatter(x=[data["frame_id"][k]], y=[data["speed"][k]], visible=True),
            go.Scatter(visible=True),
            go.Scatter(x=[data["frame_id"][k]], y=[data["throttle"][k]], visible=True),
            go.Scatter(visible=True),
            go.Scatter(x=[data["frame_id"][k]], y=[data["steer"][k]], visible=True),
            go.Scatter(visible=True),
            go.Scatter(x=[data["frame_id"][k]], y=[data["brake"][k]], visible=True),
        ]
        if (pt_type == "npy"):
            update.append(go.Scatter3d(x=data[pt_type][k][:, 0], y=data[pt_type][k][:, 1], z=data[pt_type][k][:, 2],
                                       marker=dict(color=data[pt_type][k][:, 3])))
        elif (pt_type == "sem_npy"):
            update.append(go.Scatter3d(x=data[pt_type][k][:, 0], y=data[pt_type][k][:, 1], z=data[pt_type][k][:, 2],
                                       marker=dict(color=data[pt_type][k][:, 3:6])))
        elif (pt_type == "voxel"):
            voxel_size = 1
            vertices, indexes = voxel_to_vertices(data[pt_type][k], voxel_size)
            update.append(go.Mesh3d(
                x=vertices[:, 0].flatten(),
                y=vertices[:, 1].flatten(),
                z=vertices[:, 2].flatten(),
                i = indexes[:, 0, :].flatten(),
                j = indexes[:, 1, :].flatten(),
                k = indexes[:, 2, :].flatten(),
                vertexcolor=vertices[:, 3:6],
                )
            )

        pt_frames.append(go.Frame(
            data=update,
            layout=dict(images=[
                dict(source=f"data:image/png;base64,{data['rgb_img'][k].decode()}"),
            ]),
            name=f"{data['frame_id'][k]}",
            traces=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))

    pt_fig.frames = pt_frames

    pt_sliders = [
        {
            "pad": {"b": 10, "t": 50},
            "len": 1.0,
            "x": 0,
            "y": 0,
            "steps": [
                {
                    "args": [[f.name], frame_args(FRAME_DURATION_PT)],
                    "label": f"frame {int(float(f.name))}",

                    "method": "animate",
                }
                for k, f in enumerate(pt_fig.frames)
            ],
        }
    ]

    pt_fig.update_layout(sliders=pt_sliders, updatemenus=[
        dict(type="buttons",
             buttons=[AnimationButtons.play(frame_duration=FRAME_DURATION_PT), AnimationButtons.pause()],
             showactive=False,
             x=0.5, y=0.09,
             direction="left",
             pad={"r": 10, "t": 87},
             xanchor="right",
             yanchor="top")],
                         title=f"<b>Point Cloud of {scenario}</b>")

    camera = dict(
        up=dict(x=0, y=0, z=1),
        center=dict(x=0, y=0, z=0),
        eye=dict(x=-0.7, y=0, z=0.7)
    )
    if pt_type == "npy" or pt_type == "sem_npy":
        scene = dict(
            xaxis = dict(range=[-50,50],),
            yaxis = dict(range=[-50,50],),
            zaxis = dict(range=[-50,50],),
        )
    elif pt_type == "voxel":
        scene = dict(
            xaxis = dict(range=[VOXEL_RANGE[0][0] * VOXEL_EXPAND_FACTOR, VOXEL_RANGE[0][1] * VOXEL_EXPAND_FACTOR]),
            yaxis = dict(range=[VOXEL_RANGE[1][0] * VOXEL_EXPAND_FACTOR, VOXEL_RANGE[1][1] * VOXEL_EXPAND_FACTOR]),
            zaxis = dict(range=[VOXEL_RANGE[2][0] * VOXEL_EXPAND_FACTOR, VOXEL_RANGE[2][1] * VOXEL_EXPAND_FACTOR]),
        )
    pt_fig.update_layout(
        legend=dict(x=0.98, y=1.08, xanchor='right', yanchor='top'),
        legend_orientation='h',
        scene_camera=camera,
        scene = scene,
        yaxis2=dict(range=[-1.1, 1.1]),
        yaxis3=dict(range=[-0.1, 1.1]),
        yaxis4=dict(range=[-0.1, 1.1]),
        yaxis5=dict(range=[-0.1, 1.1])

    )
 

    return pt_fig


# Draw combined figure of all the data for one frame
def draw_combined_frame(data, frame_id):

    fig = make_subplots(rows=2, cols=4,
                           specs=[[{"type": "scatter3d"}, {"type": "scatter3d"}, {"type": "scatter3d"}, {"type": "xy", "secondary_y": True}],
                                  [{"type": "image"}, {"type": "image"}, {"type": "image"}, {"type": "image"}]],
                           subplot_titles=("LIDAR", "Semanic Pointcloud", "Voxel", "Graph"),
                           vertical_spacing=0.15, horizontal_spacing=0.03, row_heights=[0.65, 0.35])
    
    fig.add_scatter3d(x=data["npy"][frame_id][:, 0], y=data["npy"][frame_id][:, 1], z=data["npy"][frame_id][:, 2],
                             mode='markers', showlegend=False, marker=dict(size=1, color=data["npy"][frame_id][:, 3]),
                             name="point cloud", row=1, col=1)
    fig.add_scatter3d(x=data["sem_npy"][frame_id][:, 0], y=data["sem_npy"][frame_id][:, 1], z=data["sem_npy"][frame_id][:, 2],
                                mode='markers', showlegend=False, marker=dict(size=1, color=data["sem_npy"][frame_id][:, 3:6]),
                                name="point cloud", row=1, col=2)
    
    voxel_size = 1
    vertices, indexes = voxel_to_vertices(data["voxel"][frame_id], voxel_size)
    fig.add_mesh3d(
        x=vertices[:, 0].flatten(),
        y=vertices[:, 1].flatten(),
        z=vertices[:, 2].flatten(),
        i = indexes[:, 0, :].flatten(),
        j = indexes[:, 1, :].flatten(),
        k = indexes[:, 2, :].flatten(),
        vertexcolor=vertices[:, 3:6],
        showscale=False,
        name='voxel',
        row=1, col=3
    )
    fig.add_scatter(x=data["frame_id"], y=data["speed"], mode="lines", name="speed", showlegend=True, secondary_y=False, row=1, col=4)
    fig.add_scatter(x=[data["frame_id"][frame_id]], y=[data["speed"][frame_id]], mode="markers", marker=dict(color="red", size=10),
                       name="speed_ball",
                       showlegend=False, row=1, col=4)
    
    fig.add_scatter(x=data["frame_id"], y=data["throttle"], mode="lines", name="throttle", showlegend=True, secondary_y=True, row=1, col=4)
    fig.add_scatter(x=[data["frame_id"][frame_id]], y=[data["throttle"][frame_id]], mode="markers", secondary_y=True,
                          marker=dict(color="red", size=10),
                          name="throttle_ball", showlegend=False, row=1, col=4)
    
    fig.add_scatter(x=data["frame_id"], y=data["steer"], mode="lines", name="steer", showlegend=True, secondary_y=True, row=1, col=4)
    fig.add_scatter(x=[data["frame_id"][frame_id]], y=[data["steer"][frame_id]], mode="markers", secondary_y=True,
                        marker=dict(color="red", size=10),
                        name="steer_ball",
                        showlegend=False, row=1, col=4)
    
    fig.add_scatter(x=data["frame_id"], y=data["brake"], mode="lines", name="brake", showlegend=True, secondary_y=True, row=1, col=4)
    fig.add_scatter(x=[data["frame_id"][frame_id]], y=[data["brake"][frame_id]], mode="markers", marker=dict(color="red", size=10),
                            name="brake_ball", secondary_y=True,
                            showlegend=False, row=1, col=4)
    
    fig.update_layout(
        template='plotly_dark')
    IMG_MARG = 0
    fig.update_layout(
        images=[
            dict(
                source='data:image/png;base64,{}'.format(data["rgb_img"][frame_id].decode()),
                xref="paper", yref="paper",
                x=0, y=0.38,
                sizex=0.325, sizey=0.325,
                xanchor="left",
                yanchor="top",
            ),
            dict(
                source='data:image/png;base64,{}'.format(data["sem_img"][frame_id].decode()),
                xref="paper", yref="paper",
                x=0.25 + IMG_MARG, y=0.38,
                sizex=0.325, sizey=0.325,
                xanchor="left",
                yanchor="top",
            ),
            dict(
                source='data:image/png;base64,{}'.format(data["depth_img"][frame_id].decode()),
                xref="paper", yref="paper",
                x=0.5 + IMG_MARG * 2, y=0.38,
                sizex=0.325, sizey=0.325,
                xanchor="left",
                yanchor="top",
            ),
            dict(
                source='data:image/png;base64,{}'.format(data["inst_img"][frame_id].decode()),
                xref="paper", yref="paper",
                x=0.75 + IMG_MARG * 3, y=0.38,
                sizex=0.325, sizey=0.325,
                xanchor="left",
                yanchor="top",
            ),
        ],
    )

    camera_vox = dict(
        up=dict(x=0, y=0, z=1),
        center=dict(x=0, y=0, z=0),
        eye=dict(x=-0.7, y=0, z=0.7)
    )

    camera_npy = dict(
        up=dict(x=0, y=0, z=1),
        center=dict(x=0, y=0, z=0),
        eye=dict(x=-0.4, y=0, z=0.4)
    )

    scene_npy = dict(
            xaxis = dict(range=[-50,50],),
            yaxis = dict(range=[-50,50],),
            zaxis = dict(range=[-50,50],),
    )

    scene_voxel = dict(
            xaxis = dict(range=[VOXEL_RANGE[0][0] * VOXEL_EXPAND_FACTOR, VOXEL_RANGE[0][1] * VOXEL_EXPAND_FACTOR]),
            yaxis = dict(range=[VOXEL_RANGE[1][0] * VOXEL_EXPAND_FACTOR, VOXEL_RANGE[1][1] * VOXEL_EXPAND_FACTOR]),
            zaxis = dict(range=[VOXEL_RANGE[2][0] * VOXEL_EXPAND_FACTOR, VOXEL_RANGE[2][1] * VOXEL_EXPAND_FACTOR]),
        )
    fig.update_layout(
        legend=dict(x=0.98, y=1.08, xanchor='right', yanchor='top'),
        legend_orientation='h',
        scene1_camera=camera_npy,
        scene2_camera=camera_npy,
        scene3_camera=camera_vox,
        scene1 = scene_npy,
        scene2 = scene_npy,
        scene3 = scene_voxel
    )

    fig.update_layout(
        title=f"<b>Visualization of {data['scenario']}</b>",
        margin=dict(r=8),
    )
    

    return fig



if __name__ == "__main__":
    main()
    # print
